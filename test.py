import os
import serial
import numpy as np
import librosa
import soundfile as sf
from scipy.io.wavfile import write

# === åƒæ•¸è¨­å®š ===
PORT = 'COM3'
BAUDRATE = 115200
DURATION = 3  # éŒ„éŸ³ç§’æ•¸
RECORD_LEN = 999999  # ä¸è¨­æ­»ç­†æ•¸ï¼Œæ ¹æ“šæ™‚é–“é‡æ¸¬å¯¦éš›é€Ÿåº¦
CENTER_VOLTAGE = 1.65
TARGET_DURATION = 1.5

# === éŒ„éŸ³ä¸¦ä¼°ç®—çœŸå¯¦å–æ¨£ç‡ ===
def record_voltage(duration_sec=DURATION):
    import time
    ser = serial.Serial(PORT, BAUDRATE)
    voltages = []
    print("ğŸ™ï¸ éŒ„éŸ³ä¸­ï¼Œè«‹é–‹å§‹èªªè©±...")

    start = time.time()
    while time.time() - start < duration_sec:
        try:
            line = ser.readline().decode().strip()
            if line:
                volt = float(line)
                voltages.append(volt)
        except:
            continue
    ser.close()
    actual_duration = time.time() - start
    print(f"âœ… éŒ„éŸ³å®Œæˆï¼Œæ”¶åˆ° {len(voltages)} ç­†ï¼Œå¯¦éš›èŠ±è²» {actual_duration:.2f} ç§’")
    real_rate = int(len(voltages) / actual_duration)
    print(f"ğŸ“Š æ¨ä¼°å–æ¨£ç‡: {real_rate} Hz")
    return np.array(voltages), real_rate

# === å‰ªè£ + è£œé½ŠèªéŸ³é•·åº¦ ===
def vad_trim_and_pad(v, sample_rate, target_duration=TARGET_DURATION, center_voltage=CENTER_VOLTAGE):
    v_centered = v - center_voltage
    v_norm = v_centered / np.max(np.abs(v_centered))
    audio_int16 = np.int16(v_norm * 32767)
    write("tmp.wav", sample_rate, audio_int16)

    y, sr = librosa.load("tmp.wav", sr=sample_rate)
    intervals = librosa.effects.split(y, top_db=20)
    if len(intervals) == 0:
        print("âš ï¸ æ²’æœ‰åµæ¸¬åˆ°èªéŸ³")
        return None
    speech = np.concatenate([y[start:end] for start, end in intervals])
    target_len = int(target_duration * sr)
    if len(speech) < target_len:
        speech = np.pad(speech, (0, target_len - len(speech)))
    else:
        speech = speech[:target_len]
    return speech

# === MFCC ç‰¹å¾µ ===
def extract_mfcc(waveform, sr):
    mfcc = librosa.feature.mfcc(y=waveform, sr=sr, n_mfcc=13)
    return mfcc.T

# === æ”¶é›†ä¸€ç­†è³‡æ–™ ===
def collect_sample(command_name):
    voltages, real_rate = record_voltage()

    speech = vad_trim_and_pad(voltages, sample_rate=real_rate)
    if speech is None:
        return

    # å„²å­˜ wav
    save_dir = os.path.join("dataset", command_name)
    os.makedirs(save_dir, exist_ok=True)
    count = len([f for f in os.listdir(save_dir) if f.endswith(".wav")]) + 1
    wav_path = os.path.join(save_dir, f"{command_name}_{count:03d}.wav")
    sf.write(wav_path, speech, real_rate)
    print(f"ğŸ’¾ å·²å„²å­˜èªéŸ³æª”: {wav_path}")

    # å„²å­˜ mfcc
    mfcc = extract_mfcc(speech, real_rate)
    npy_path = os.path.join(save_dir, f"{command_name}_{count:03d}.npy")
    np.save(npy_path, mfcc)
    print(f"ğŸ’¾ å·²å„²å­˜ MFCC ç‰¹å¾µ: {npy_path}, shape={mfcc.shape}")

# === åŸ·è¡Œ ===
if __name__ == "__main__":
    while True:
        cmd = input("ğŸ”¤ è«‹è¼¸å…¥æŒ‡ä»¤åç¨±ï¼ˆæˆ– q é›¢é–‹ï¼‰ï¼š").strip().lower()
        if cmd == "q":
            break
        collect_sample(cmd)
